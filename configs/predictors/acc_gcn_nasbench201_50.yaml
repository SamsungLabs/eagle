predictor:
    num_features: 6
    num_layers: 4
    num_hidden: 600
    dropout_ratio: 0.2
    weight_init: thomas
    bias_init: thomas

training:
    epochs: 250
    learning_rate: 3.5e-4
    weight_decay: 5.0e-4
    lr_patience: 10
    es_patience: 35
    batch_size: 32
    shuffle: True
    optim_name: adamw
    lr_scheduler: cosine

dataset:
    total_points: 15284
    training_points: 50
    validation_points: 50
    sampling_method: 'random'
    sampling_seed: !!null
